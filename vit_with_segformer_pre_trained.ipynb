{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V7qRrTC7wud"
      },
      "source": [
        "# Implementation of Vision Transformer for building segmentation from INRIA aerial image labeling dataset using PyTorch with SegFormer pre-trained weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8YTa39a7wuh"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d sagar100rathod/inria-aerial-image-labeling-dataset"
      ],
      "metadata": {
        "id": "TmK95rBs8GhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data\n",
        "! unzip inria-aerial-image-labeling-dataset.zip -d data"
      ],
      "metadata": {
        "id": "_nKNXoU389SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USY_SMEk7wuh"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import functional as F\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFogJ5l57wui"
      },
      "outputs": [],
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Pj6Pi97wuj"
      },
      "source": [
        "### Set device and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjsVWMaS7wuj"
      },
      "outputs": [],
      "source": [
        "# Set device to run on GPU if available\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# Set hyperparameters\n",
        "patch_size = 16\n",
        "latent_size = 768 # Embedding dimension (or latent vector) (16x16x3) (patch size 16x16) x3 color channels\n",
        "n_channels = 3 # Number of channels for input images\n",
        "num_heads = 12 # Number of head\n",
        "num_encoders = 12 # Number of encoder layers\n",
        "dropout = 0.1\n",
        "size = 224  # Size of the input image\n",
        "num_labels = 1 # Number of output labels (Building/Not building)\n",
        "\n",
        "epochs = 40\n",
        "lr = 1e-3   # Learning rate\n",
        "weight_decay = 0.03    # Weight decay\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8-J4xD67wuj"
      },
      "source": [
        "### Preprocess the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtthpqB77wuj"
      },
      "source": [
        "#### For training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5hzt19j7wuj"
      },
      "outputs": [],
      "source": [
        "# Calculate mean and standard deviation of the training images across all channels (R, G, B) for normalizing the dataset\n",
        "def compute_mean_std(image_dir):\n",
        "    training_images = os.listdir(image_dir)\n",
        "\n",
        "    # Initialize mean and std\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    num_pixels = 0\n",
        "\n",
        "    # Process each image\n",
        "    for training_image in tqdm(training_images, desc=\"Processing images\"):\n",
        "        img_path = os.path.join(image_dir, training_image)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Convert image to tensor\n",
        "        img_tensor = ToTensor()(image) # Convert image to (C, H, W) tensor\n",
        "        # Calculate number of pixels\n",
        "        num_pixels += img_tensor.size(1) * img_tensor.size(2)\n",
        "        # Sum the mean and squared mean of each channel\n",
        "        mean += img_tensor.sum(dim=[1, 2])\n",
        "        std += (img_tensor ** 2).sum(dim=[1, 2])\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean /= num_pixels\n",
        "    std = (std / num_pixels - mean ** 2).sqrt()\n",
        "\n",
        "    return mean.tolist(), std.tolist()\n",
        "\n",
        "image_dir = \"data/AerialImageDataset/train/images\"\n",
        "mean, std = compute_mean_std(image_dir)\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxiFMSfG7wuk"
      },
      "outputs": [],
      "source": [
        "# Resize the input images to 224x224\n",
        "transform_training_data = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.4048401415348053, 0.427262544631958, 0.3927135467529297],\n",
        "              std=[0.20133039355278015, 0.1835126429796219, 0.17614711821079254])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qICq3yqq7wuk"
      },
      "outputs": [],
      "source": [
        "# Class for INRIA training dataset\n",
        "class INRIATrainDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[index])\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L') # Convert mask to grayscale\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            # Resize the mask to (224, 224) and convert to tensor\n",
        "            mask = Resize((56, 56))(mask)  # Resize the mask\n",
        "            mask = F.to_tensor(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "image_dir = 'data/AerialImageDataset/train/images'\n",
        "mask_dir = 'data/AerialImageDataset/train/gt'\n",
        "\n",
        "train_data = INRIATrainDataset(image_dir, mask_dir, transform=transform_training_data)\n",
        "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaoj_WJO7wuk"
      },
      "source": [
        "### Visualize the training data (image and mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRen8mi67wuk"
      },
      "outputs": [],
      "source": [
        "# Unnormalize the dataset for visualization\n",
        "def unnormalized(tensor, mean, std):\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return tensor\n",
        "\n",
        "# Visualize the some preprocessed data\n",
        "def visualize_dataset(dataset, num_samples=5):\n",
        "    mean = [0.4048401415348053, 0.427262544631958, 0.3927135467529297]\n",
        "    std = [0.20133039355278015, 0.1835126429796219, 0.17614711821079254]\n",
        "\n",
        "    fig, axis = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
        "    for i in range(num_samples):\n",
        "        image, mask = dataset[i]\n",
        "\n",
        "        # Unnormalize image for visualization\n",
        "        image = unnormalized(image.clone(), mean, std)  # Clone to avoid modify the preprocessed data\n",
        "        image_np = image.permute(1, 2, 0).cpu().numpy()  # Convert image tensor to (height, width, channel)\n",
        "        mask_np = mask.squeeze().cpu().numpy()    # Convert mask tensor to numpy\n",
        "\n",
        "        # Show the image and corresponding mask\n",
        "        axis[i, 0].imshow(image_np)\n",
        "        axis[i, 0].set_title(f\"Image {i+1}\")\n",
        "        axis[i, 0].axis('off')\n",
        "\n",
        "        axis[i, 1].imshow(mask_np, cmap='gray')\n",
        "        axis[i, 1].set_title(f\"Mask {i+1}\")\n",
        "        axis[i, 1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize_dataset(train_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8wZfxg97wuk"
      },
      "source": [
        "#### For test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLbKWcWm7wuk"
      },
      "outputs": [],
      "source": [
        "# Calculate mean and standard deviation of the test images across all channels (R, G, B) for normalizing the dataset\n",
        "def compute_mean_std(image_dir):\n",
        "    test_images = os.listdir(image_dir)\n",
        "\n",
        "    # Initialize mean and std\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    num_pixels = 0\n",
        "\n",
        "    # Process each image\n",
        "    for training_image in tqdm(test_images, desc=\"Processing test images\"):\n",
        "        img_path = os.path.join(image_dir, training_image)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Convert image to tensor\n",
        "        img_tensor = ToTensor()(image) # Convert image to (C, H, W) tensor\n",
        "        # Calculate number of pixels\n",
        "        num_pixels += img_tensor.size(1) * img_tensor.size(2)\n",
        "        # Sum the mean and squared mean of each channel\n",
        "        mean += img_tensor.sum(dim=[1, 2])\n",
        "        std += (img_tensor ** 2).sum(dim=[1, 2])\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean /= num_pixels\n",
        "    std = (std / num_pixels - mean ** 2).sqrt()\n",
        "\n",
        "    return mean.tolist(), std.tolist()\n",
        "\n",
        "image_dir = \"data/AerialImageDataset/test/images\"\n",
        "mean, std = compute_mean_std(image_dir)\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOrKvC-07wul"
      },
      "outputs": [],
      "source": [
        "# Define transformations (e.g., resize, normalize) for test set images\n",
        "test_transforms = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.4543627202510834, 0.47366490960121155, 0.4127490520477295],\n",
        "              std=[0.20975154638290405, 0.1924573928117752, 0.18913407623767853])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnXLS0Q7wul"
      },
      "outputs": [],
      "source": [
        "# Class for INRIA test dataset\n",
        "class INRIATestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "image_dir = 'data/AerialImageDataset/test/images'\n",
        "\n",
        "test_data = INRIATestDataset(image_dir, transform=transform_training_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWZbKSBY7wul"
      },
      "source": [
        "### Visualize test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZAJuBm57wul"
      },
      "outputs": [],
      "source": [
        "# Unnormalize the dataset for visualization\n",
        "def unnormalized(tensor, mean, std):\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return tensor\n",
        "\n",
        "# Visualize the some preprocessed data\n",
        "def visualize_dataset(dataset, num_samples=5):\n",
        "    mean = [0.4543627202510834, 0.47366490960121155, 0.4127490520477295]\n",
        "    std = [0.20975154638290405, 0.1924573928117752, 0.18913407623767853]\n",
        "\n",
        "    fig, axis = plt.subplots(num_samples, 1, figsize=(10, num_samples * 5))\n",
        "    for i in range(num_samples):\n",
        "        image = dataset[i]\n",
        "\n",
        "        # Unnormalize image for visualization\n",
        "        image = unnormalized(image.clone(), mean, std)  # Clone to avoid modify the preprocessed data\n",
        "        image_np = image.permute(1, 2, 0).cpu().numpy()  # Convert image tensor to (height, width, channel)\n",
        "\n",
        "        # Show the image and corresponding mask\n",
        "        axis[i].imshow(image_np)\n",
        "        axis[i].set_title(f\"Test Image {i+1}\")\n",
        "        axis[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_dataset(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the SegFormer pre-trained weight"
      ],
      "metadata": {
        "id": "ivLP1iD_RfiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
        "# Pre-trained SegFormer (from Hugging Face)\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    \"nvidia/mit-b0\",\n",
        "    num_labels=num_labels\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "nOS_JbrzFuwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BCELossWithLogits for binary classification\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "def iou_score(preds, targets, threshold=0.5):\n",
        "    # Apply sigmoid and threshold to get binary predictions\n",
        "    preds = torch.sigmoid(preds) > threshold\n",
        "\n",
        "    # Flatten predictions and targets\n",
        "    preds_flat = preds.view(-1).float()\n",
        "    targets_flat = targets.view(-1).float()\n",
        "\n",
        "    intersection = (preds_flat * targets_flat).sum()\n",
        "    union = preds_flat.sum() + targets_flat.sum() - intersection\n",
        "\n",
        "    return (intersection + 1e-6) / (union + 1e-6)\n",
        "\n"
      ],
      "metadata": {
        "id": "TrHkDLzuGzYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune SegFormer\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    # Lists to store the loss and IoU scores for each epoch\n",
        "    loss_history = []\n",
        "    iou_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_iou = 0.0\n",
        "\n",
        "        for images, masks in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images).logits\n",
        "            loss = criterion(outputs, masks)\n",
        "            iou = iou_score(outputs, masks)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_iou += iou.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_iou = running_iou / len(dataloader)\n",
        "\n",
        "        loss_history.append(epoch_loss)\n",
        "        iou_history.append(epoch_iou)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Loss: {epoch_loss}, IoU: {epoch_iou}\")\n",
        "\n",
        "    # Plot IoU score over epochs\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, epochs+1), iou_history, label=\"IoU Score\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"IoU Score\")\n",
        "    plt.title(\"IoU Score Over Epochs\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Train the model\n",
        "train_model(model, trainloader, criterion, optimizer, epochs=40)"
      ],
      "metadata": {
        "id": "DaYDniTJG4fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict on test set images"
      ],
      "metadata": {
        "id": "oFwV4IduR-AY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eft3AQgN7wun"
      },
      "outputs": [],
      "source": [
        "# Function to make predictions on the test set\n",
        "def predict_and_visualize(model, testloader, num_samples=5):\n",
        "    mean = [0.4543627202510834, 0.47366490960121155, 0.4127490520477295]\n",
        "    std = [0.20975154638290405, 0.1924573928117752, 0.18913407623767853]\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    fig, axis = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
        "    with torch.no_grad():\n",
        "        for i, image in enumerate(testloader):\n",
        "            if i == num_samples:\n",
        "                break\n",
        "\n",
        "            image = image.to(device)\n",
        "            pred_mask = model(image)  # Make prediction\n",
        "            # Access the logits from the SemanticSegmenterOutput object\n",
        "            logits = pred_mask.logits  # This extracts the tensor from the output object\n",
        "\n",
        "            # Apply sigmoid for binary segmentation\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "\n",
        "            # Apply threshold to convert probabilities into binary predictions\n",
        "            pred_mask = (probabilities > 0.5).float()\n",
        "            pred_mask = pred_mask.squeeze().cpu().numpy()  # Convert to numpy array\n",
        "\n",
        "            # Unnormalize the image for display\n",
        "            image = unnormalized(image.clone(), mean, std)\n",
        "            image_np = image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            # Display the image and predicted mask\n",
        "            axis[i, 0].imshow(image_np)\n",
        "            axis[i, 0].set_title(f\"Test Image {i+1}\")\n",
        "            axis[i, 0].axis('off')\n",
        "\n",
        "            axis[i, 1].imshow(pred_mask, cmap='gray')\n",
        "            axis[i, 1].set_title(f\"Predicted Mask {i+1}\")\n",
        "            axis[i, 1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Load test data and visualize\n",
        "testloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "predict_and_visualize(model, testloader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}